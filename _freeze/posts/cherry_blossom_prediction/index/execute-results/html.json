{
  "hash": "aba11ceb58a821e8990a24e02ddd57c2",
  "result": {
    "markdown": "---\ntitle: \"Cherry Blossom prediction using Time Series\"\nsubtitle: \"A time series analysis to forecast 2024 cherry blossom bloom date\"\nauthor: \"Aditya Ranade\"\ndate: \"2024-03-01\"\ndate-modified: last-modified\ncategories: [analysis]\nimage: \"cherry_blossom.jpg\"\n---\n\n\n::: {style=\"text-align: justify\"}\nCherry Blossom is one of the most scenic visuals one can experience. In the recent past, cherry blossom season marks the arrival of spring season which can be considered as a transition from winter to summer. People try to make plans travel to enjoy this phenomenon. So how about using some simple statistical techniques to try and forecast / predict the peak cherry blossom time ?\n:::\n\n::: {style=\"text-align: justify\"}\nAlong with some of my fellow PhD classmates, I participated in the International Cherry Blossom Prediction Competition hosted by George Mason university. We explored a lot of models and I am going to show a very basic model which I tried during the early stages. The model is the Autogegressive (AR) model. The notation of this model is AR(1) model is as follows\n\n:::\n\n$$\nY_{t} = \\beta_{1} Y_{t-1} + \\epsilon_{t}\n$$\nwhere $\\beta_{i}$ is the model parameter and $\\epsilon_{t}$ is the white noise\n\n\n::: {style=\"text-align: justify\"}\nThis simply means the present value of the response variable (in our case the bloom day in this year) is influenced by the previous value fo the response variable (in our case the bloom day of the previous year). If you are aware of the simple linear regression, think of this as the explanatory variable being the same as the predictor variable in rough sense. In the competition, we tried to predict the bloom date for multiple location across the world based on the data available provide by the university. However, for the purpose of this post, I will show the analysis only for one location, Kyoto in Japan.\n:::\n\n::: {style=\"text-align: justify\"}\nLet us start with first reading in the dataset and loading the R packages required for the analysis\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the packages\nlibrary(forecast)\nlibrary(ggplot2)\nlibrary(fpp2)\nlibrary(dplyr)\nlibrary(vars)\n\n# Load the dataset\nkyoto <- read.csv(\"https://raw.githubusercontent.com/GMU-CherryBlossomCompetition/peak-bloom-prediction/main/data/kyoto.csv\",header=T)\n\n# Plot of the bloom date over the years\nggplot(kyoto,aes(x=year,y=bloom_doy))+\n  geom_point()+\n  theme_minimal()+\n  labs(x=\"Year\",y=\"Bloom Day\")+\n  ggtitle(\"Bloom Day by Year\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/load-packages-1.png){width=672}\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nAs we can see from the plot, towards the later end which means in the recent past, the bloom day has started to go down. Let us look at the plot only from the year 1950 onwards.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter data only for year since 1951\nkyoto_new <- kyoto %>% filter(year>1950)\n\n# Plot of the bloom date over the years\nggplot(kyoto_new,aes(x=year,y=bloom_doy))+\n  geom_point()+\n  theme_minimal()+\n  labs(x=\"Year\",y=\"Bloom Day\")+\n  ggtitle(\"Bloom Day by Year\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/filter-data-1.png){width=672}\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nAs we can see from the plot from year 1951 onward, there seems to be a downward trend which indicates the bloom date is in general going down.\n:::\n\n::: {style=\"text-align: justify\"}\nWe will use the data from 1951 to 2022 to predict the bloom date for year 2023 and compare that to actual bloom date. For this, we will use the bloom day as response and the year as the predictor\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare the data for ARIMA(1,0,0) model\ny_kyoto <- kyoto_new$bloom_doy # bloom day as the response\n```\n:::\n\n\n\nExclude the year 2023 response and explanatory variable to test the model on year 2023\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First test on 2023 model\nytest <- y_kyoto[-length(y_kyoto)] # exclude the bloom day for 2023 year\n\n# Model based on year 1951 to 2022\nfit_kyoto_test <- Arima(ytest, order=c(1,0,0))\nfit_kyoto_test\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: ytest \nARIMA(1,0,0) with non-zero mean \n\nCoefficients:\n         ar1     mean\n      0.2307  97.5165\ns.e.  0.1154   0.6759\n\nsigma^2 = 20.18:  log likelihood = -209.35\nAIC=424.69   AICc=425.04   BIC=431.52\n```\n:::\n\n```{.r .cell-code}\n#Forecast\nfcast_kyoto_test <- forecast(fit_kyoto_test)\nfcast_kyoto_test\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\n73       96.01338 90.25636 101.7704 87.20878 104.8180\n74       97.16981 91.26162 103.0780 88.13401 106.2056\n75       97.43656 91.52043 103.3527 88.38863 106.4845\n76       97.49809 91.58154 103.4146 88.44951 106.5467\n77       97.51229 91.59572 103.4289 88.46367 106.5609\n78       97.51556 91.59899 103.4321 88.46694 106.5642\n79       97.51631 91.59974 103.4329 88.46770 106.5649\n80       97.51649 91.59992 103.4331 88.46787 106.5651\n81       97.51653 91.59996 103.4331 88.46791 106.5651\n82       97.51654 91.59997 103.4331 88.46792 106.5652\n```\n:::\n\n```{.r .cell-code}\n# Check actual bloom date for 2023\ny_kyoto[length(y_kyoto)] #84 \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 84\n```\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nThe AR(1) model predicts 96 as the bloom day for year 2023 whereas the actual bloom day was 84 for year 2023 which is a difference of 12 days. Considering its a basic model, this does not seem to be too bad.\n:::\n\n::: {style=\"text-align: justify\"}\nNow we check the performance of the model using some charts where we first check the prediction plot, then the Regression and model errors. \n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the prediction\nautoplot(fcast_kyoto_test) + xlab(\"Year\") +\n  ylab(\"Percentage change\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/f2023-plots 1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# recover estimates of nu(t) and epsilon(t) \ncbind(\"Regression Errors\" = residuals(fit_kyoto_test, type=\"regression\"),\n      \"ARIMA errors\" = residuals(fit_kyoto_test, type=\"innovation\")) %>%\n  autoplot(facets=TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/f2023-plots 1-2.png){width=672}\n:::\n:::\n\n\n\n::: {style=\"text-align: justify\"}\nThere does not seem to be any issues with either of the plots. Now we check the residuals to see if they are normally distributed.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check the residuals\ncheckresiduals(fit_kyoto_test)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/f2023-plots 2-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(1,0,0) with non-zero mean\nQ* = 10.055, df = 9, p-value = 0.346\n\nModel df: 1.   Total lags used: 10\n```\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nThe residuals seem to be normally distributed and the Ljung-Box test indicates we have little evidence against the null hypothesis of independently distributed errors.\n:::\n\n::: {style=\"text-align: justify\"}\nNow we will use the data from 1951 upto 2023 to predict the bloom date for the year 2024. Basically its the same model with one extra data point available\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Now use data upto 2023 to predict 2024\nfit_kyoto <- Arima(y_kyoto, order=c(1,0,0))\nfit_kyoto\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: y_kyoto \nARIMA(1,0,0) with non-zero mean \n\nCoefficients:\n         ar1     mean\n      0.2821  97.2885\ns.e.  0.1182   0.7483\n\nsigma^2 = 21.84:  log likelihood = -215.16\nAIC=436.32   AICc=436.67   BIC=443.19\n```\n:::\n\n```{.r .cell-code}\n#Forecast\nfcast_kyoto <- forecast(fit_kyoto,xreg = 2024)\nfcast_kyoto\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\n74       93.53975 87.55120  99.5283 84.38105 102.6984\n75       96.23094 90.00866 102.4532 86.71479 105.7471\n76       96.99013 90.74963 103.2306 87.44611 106.5342\n77       97.20430 90.96235 103.4463 87.65806 106.7505\n78       97.26472 91.02265 103.5068 87.71830 106.8111\n79       97.28176 91.03969 103.5238 87.73533 106.8282\n80       97.28657 91.04450 103.5286 87.74014 106.8330\n81       97.28793 91.04585 103.5300 87.74150 106.8344\n82       97.28831 91.04624 103.5304 87.74188 106.8347\n83       97.28842 91.04634 103.5305 87.74199 106.8349\n```\n:::\n:::\n\n\n:::{style=\"text-align: justify\"}\nThe model predicts the cherry blossom to bloom on day 95 which is April 4th for Kyoto, Tokyo. Now lets look at the diagnostics of the model to see if the model is reasonable.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the forecast\nautoplot(fcast_kyoto) + xlab(\"Year\") +\n  ylab(\"Percentage change\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/forecast-2024 p2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# recover estimates of nu(t) and epsilon(t) \ncbind(\"Regression Errors\" = residuals(fit_kyoto, type=\"regression\"),\n      \"ARIMA errors\" = residuals(fit_kyoto, type=\"innovation\")) %>%\n  autoplot(facets=TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/forecast-2024 p2-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Check the residuals\ncheckresiduals(fit_kyoto)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/forecast-2024 p2-3.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(1,0,0) with non-zero mean\nQ* = 13.92, df = 9, p-value = 0.1252\n\nModel df: 1.   Total lags used: 10\n```\n:::\n:::\n\n\n::: {style=\"text-align: justify\"}\nAgain, the residuals seem to be normally distributed and the Ljung-Box test indicates we have little evidence against the null hypothesis of independently distributed errors. \n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}